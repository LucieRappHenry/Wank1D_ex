{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ccefc3c",
   "metadata": {},
   "source": [
    "# Notebook for analysing simulation outputs\n",
    "\n",
    "## Summary\n",
    "* [1. Read & Process simulation outputs](#t1)\n",
    "* [2. Processing simulation outputs](#t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61998aa",
   "metadata": {},
   "source": [
    "## 1. Read & Process simulation outputs <a class=\"anchor\" id=\"t1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cceea23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os,glob,struct\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from parflow import read_pfb, read_pfb_sequence, ParflowBinaryReader\n",
    "from parflow import Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10c1df53",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/hectorb/PARFLOW/PROJECTS/test_cases/hillslope/ara_bele/simus/\"\n",
    "wdir = root_dir+'results_benchmark/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87854eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_process_pf_outputs(wdir,date_start=\"2005-01-01\"):\n",
    "    # read header\n",
    "    with ParflowBinaryReader(glob.glob(wdir+'*.press.00000.pfb')[0]) as s: h = s.header\n",
    "    print(h)\n",
    "    \n",
    "    # get z\n",
    "    var_dz = read_pfb(glob.glob(wdir+'*mult*.pfb')[0])\n",
    "    var_dz_vec = var_dz[:,0,0]\n",
    "    var_dz_vec = var_dz_vec[::-1]\n",
    "    dz = var_dz_vec * h['dz']\n",
    "    z = np.cumsum(dz) - var_dz_vec/2 \n",
    "    \n",
    "    # get pressure (pop(0) skips initial condition)\n",
    "    files = np.sort(glob.glob(wdir+'*.press.*.pfb'))[1::]\n",
    "    press = read_pfb_sequence(files)\n",
    "    \n",
    "    # get saturation\n",
    "    files = np.sort(glob.glob(wdir+'*.satur.*.pfb'))[1::]\n",
    "    satur = read_pfb_sequence(files)\n",
    "    \n",
    "    # get evaptranssum\n",
    "    files = np.sort(glob.glob(wdir+'*.evaptranssum.*.pfb'))\n",
    "    evaptranssum = read_pfb_sequence(files)\n",
    "        \n",
    "    # get overlandsum\n",
    "    files = np.sort(glob.glob(wdir+'*.overlandsum.*.pfb'))\n",
    "    overlandsum = read_pfb_sequence(files)\n",
    "        \n",
    "    # create dataset\n",
    "    ds = xr.Dataset({\"press\": ((\"time\",\"z\",\"y\"), press[:,::-1,:,0]),\n",
    "                    \"satur\": ((\"time\",\"z\",\"y\"), satur[:,::-1,:,0]),\n",
    "                    \"evaptranssum\": ((\"time\",\"z\",\"y\"), evaptranssum[:,::-1,:,0]),\n",
    "                    \"overlandsum\":((\"time\",\"y\"), overlandsum[:,0,:,0]),\n",
    "                    'vdz': ((\"z\",\"y\",\"x\"),var_dz[::-1,:,:])},\n",
    "        coords={\"x\":np.arange(start = h['x'],stop = h['x']+h['nx']*h['dx'],step=h['dx']),\n",
    "            \"y\":np.arange(start = h['y'],stop = h['y']+h['ny']*h['dy'],step=h['dy']),\n",
    "            \"z\":-z, \n",
    "            \"time\": pd.date_range(date_start, periods=len(files)),\n",
    "            \"reference_time\": pd.Timestamp(date_start)})\n",
    "\n",
    "    # add WTD:\n",
    "    ds = ds.assign(WTD = z[-1] - ds.press.isel(z=-1))\n",
    "\n",
    "    # add auxiliary variables:\n",
    "    ds = ds.assign(poro=((\"z\",\"y\",\"x\"),read_pfb(glob.glob(wdir+'*poro*.pfb')[0])[::-1,:,:]))\n",
    "    ds = ds.assign(specstor=((\"z\",\"y\",\"x\"),read_pfb(glob.glob(wdir+'*specific*.pfb')[0])[::-1,:,:]))    \n",
    "\n",
    "    # compute storage:\n",
    "    ds = ds.assign(storage_cbyc=lambda x: h['dx']*h['dy']*h['dz']*x.vdz*x.poro*x.satur + \\\n",
    "                                        h['dx']*h['dy']*h['dz']*x.vdz*x.specstor*x.poro*x.satur*x.press + \\\n",
    "                                        xr.where((x.z==x.z[0]) & (x.press>0),h['dx']*h['dy']*x.press,0))\n",
    "    ds = ds.assign(storage=lambda x: x.storage_cbyc.sum(dim=('x','z')))\n",
    "\n",
    "    \n",
    "    \n",
    "    ds.press.attrs['units']='m'\n",
    "    ds.satur.attrs['units']='m3/m3'\n",
    "    ds.evaptranssum.attrs['units']='m3/PFtimestep'\n",
    "    ds.overlandsum.attrs['units']='m3/PFtimestep' \n",
    "    ds.storage.attrs['units']='m3'\n",
    "    ds.storage_cbyc.attrs['units']='m3'  \n",
    "    ds.y.attrs['units']='meters'\n",
    "    ds.z.attrs['units']='meters'\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7243f883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 0.0, 'y': 0.0, 'z': 0.0, 'nx': 1, 'ny': 50, 'nz': 24, 'dx': 10.0, 'dy': 10.0, 'dz': 1.0, 'n_subgrids': 2, 'p': 1, 'q': 2, 'r': 1}\n"
     ]
    }
   ],
   "source": [
    "ds1 = read_and_process_pf_outputs(root_dir+'results_benchmark/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47ea5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_OVFLOW(width,manning,slope,h):\n",
    "    \"\"\"\n",
    "    simple function which return the overland flux from one cell to another across one cell\n",
    "    \"\"\"\n",
    "    return (width/manning)*(slope**0.5)*h**(5./3.)\n",
    "\n",
    "\n",
    "def calculate_runoff_from_press(htop,slopex,slopey,dx,dy,m):\n",
    "    \"\"\"\n",
    "    compute runoff at single location\n",
    "    htop dim is time\n",
    "    \"\"\"\n",
    "    Sy = np.abs(slopey)\n",
    "    Sx = np.abs(slopex)\n",
    "    return np.where(htop>0,np.abs(calculate_OVFLOW(dy,m,Sx,htop))+np.abs(calculate_OVFLOW(dx,m,Sy,htop)),0)\n",
    "\n",
    "def read_clm_outputs(wdir,date_start=\"2005-01-01\"):\n",
    "    # read header\n",
    "    with ParflowBinaryReader(glob.glob(wdir+'*.press.00000.pfb')[0]) as s: h = s.header\n",
    "    print(h)    \n",
    "    \n",
    "    # get z\n",
    "    var_dz = read_pfb(glob.glob(wdir+'*mult*.pfb')[0])\n",
    "    var_dz_vec = var_dz[:,0,0]\n",
    "    var_dz_vec = var_dz_vec[::-1]\n",
    "    dz = var_dz_vec * h['dz']\n",
    "    z = np.cumsum(dz) - var_dz_vec/2 \n",
    "    \n",
    "    files = np.sort(glob.glob(wdir+'*.clm_output.*.pfb'))\n",
    "    clms = read_pfb_sequence(files)\n",
    "    # create dataset\n",
    "    ds = xr.Dataset({\"lh_tot\": ((\"time\",\"y\"), clms[:,0,:,0]),\n",
    "                    \"lwrad_out\": ((\"time\",\"y\"), clms[:,1,:,0]),\n",
    "                    \"sh_tot\": ((\"time\",\"y\"), clms[:,2,:,0]),\n",
    "                    \"soil_grnd\": ((\"time\",\"y\"), clms[:,3,:,0]),\n",
    "                    \"evap_tot\": ((\"time\",\"y\"), clms[:,4,:,0]*60*60),\n",
    "                    \"evap_grnd\": ((\"time\",\"y\"), clms[:,5,:,0]*60*60),\n",
    "                    \"evap_soi\": ((\"time\",\"y\"), clms[:,6,:,0]*60*60),\n",
    "                    \"evap_veg\": ((\"time\",\"y\"), clms[:,7,:,0]*60*60),\n",
    "                    \"tran_veg\": ((\"time\",\"y\"), clms[:,8,:,0]*60*60),\n",
    "                    \"infl\": ((\"time\",\"y\"), clms[:,9,:,0]*60*60),\n",
    "                    \"swe_out\": ((\"time\",\"y\"), clms[:,10,:,0]),\n",
    "                    \"t_grnd\": ((\"time\",\"y\"), clms[:,11,:,0]),\n",
    "                    \"htop\": ((\"time\",\"y\"), clms[:,12,:,0])},\n",
    "\n",
    "        coords={\n",
    "            \"y\":np.arange(start = h['y'],stop = h['y']+h['ny']*h['dy'],step=h['dy']),\n",
    "                    \"z\":-z,\n",
    "            \"time\": pd.date_range(date_start, periods=len(files),freq='1H'),\n",
    "            \"reference_time\": pd.Timestamp(date_start)})\n",
    "\n",
    "    ds = ds.assign(slopex=((\"y\",\"x\"),read_pfb(glob.glob(wdir+'*slope_x*.pfb')[0])[0,:,:]))\n",
    "    ds = ds.assign(slopey=((\"y\",\"x\"),read_pfb(glob.glob(wdir+'*slope_y*.pfb')[0])[0,:,:]))\n",
    "\n",
    "    ds.lh_tot.attrs['units']='$W/m^2$'\n",
    "    ds.lwrad_out.attrs['units']='$W/m^2$'\n",
    "    ds.sh_tot.attrs['units']='$W/m^2$'\n",
    "    ds.soil_grnd.attrs['units']='$W/m^2$'\n",
    "    ds.evap_tot.attrs['units']='mm/h'\n",
    "    ds.evap_grnd.attrs['units']='mm/h'\n",
    "    ds.evap_soi.attrs['units']='mm/h'\n",
    "    ds.evap_veg.attrs['units']='mm/h'\n",
    "    ds.tran_veg.attrs['units']='mm/h'\n",
    "    ds.infl.attrs['units']='mm/h'\n",
    "    ds.swe_out.attrs['units']='mm'\n",
    "    ds.t_grnd.attrs['units']='K'\n",
    "    ds.htop.attrs['units']='m'\n",
    "\n",
    "    ds.y.attrs['units']='meters'\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c57ac7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 0.0, 'y': 0.0, 'z': 0.0, 'nx': 1, 'ny': 50, 'nz': 24, 'dx': 10.0, 'dy': 10.0, 'dz': 1.0, 'n_subgrids': 2, 'p': 1, 'q': 2, 'r': 1}\n"
     ]
    }
   ],
   "source": [
    "dc1 = read_clm_outputs(root_dir+'results_benchmark/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80db20bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc1 = dc1.assign(slopex=((\"y\",\"x\"),read_pfb(glob.glob(wdir+'*slope_x*.pfb')[0])[0,:,:]))\n",
    "dc1 = dc1.assign(slopey=((\"y\",\"x\"),read_pfb(glob.glob(wdir+'*slope_y*.pfb')[0])[0,:,:]))\n",
    "dc1 = dc1.assign(mask=((\"z\",\"y\",\"x\"),read_pfb(glob.glob(wdir+'*mask*.pfb')[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83ee6dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " => Error during CLM import - CLM specific key have been skipped\n"
     ]
    }
   ],
   "source": [
    "hill = Run.from_definition(root_dir+'hillslope.pfidb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b52016ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16800/289806870.py:5: RuntimeWarning: invalid value encountered in power\n",
      "  return (width/manning)*(slope**0.5)*h**(5./3.)\n"
     ]
    }
   ],
   "source": [
    "manning = hill.Mannings.Geom.domain.Value\n",
    "dc1 = dc1.assign(Q=lambda x: ('time',calculate_runoff_from_press(x.htop.data[:,0],\n",
    "                                                         x.slopex.data[0,0],\n",
    "                                                         x.slopey.data[0,0],\n",
    "                                                         10,10,manning)))\n",
    "dc1.Q.attrs['units']='m3/CLMtimestep'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10086252",
   "metadata": {},
   "source": [
    "## 2. Processing simulation outputs <a class=\"anchor\" id=\"t2\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
